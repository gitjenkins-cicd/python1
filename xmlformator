from bs4 import BeautifulSoup
import csv
with open('sample.xml', 'r') as f:
    data = f.read()
Bs_data = BeautifulSoup(data, "xml")
#datalist=["responseHeader","responseData"]
#for header in datalist:
b_unique = Bs_data.find_all('responseHeader')

#for x in b_unique:
 # print(x)
#print(b_unique)
with open('responseheader.csv', 'w') as f:
  write = csv.writer(f)
  for x in b_unique:
    write.writerow(x)


https://drive.google.com/file/d/1yS-E9dg-clCWSBn7tIli2syHX-U31npf/view?usp=sharing

var1=$(date '+%Y-%m-%d %H:%M:%S'|awk -F: '{ print ($1 * 3600) + ($2 * 60) + $3 }')
sleep 20
var2=$(date '+%Y-%m-%d %H:%M:%S'|awk -F: '{ print ($1 * 3600) + ($2 * 60) + $3 }')
diff=$(expr $var2 - $var1)
m=60
min=$(bc <<<"scale=2; $diff/$m")


sed -i 's/httpsample/buildid": "'$build'", "httpsample/' outfile1.ndl

sed 's/testResults version="1.2"/testResults version="1.2" buildid: "'$buildid'"/' error.xml

Bigquery Timepartition

https://medium.com/google-cloud/partition-on-any-field-with-bigquery-840f8aa1aaab
https://levelup.gitconnected.com/optimizing-your-bigquery-tables-using-partitioning-time-unit-column-partitioned-tables-c93cfbf3828d
https://hevodata.com/learn/bigquery-partition/
https://fivetran.com/docs/destinations/bigquery/partition-table

Bigquery insert command:

INSERT INTO `shakeersreboot.sre_dataset.partitionedtable` (Date1,msg,url,responsecode,errormsg,connect,idletime,delaytime)
SELECT Date,msg,url,responsecode,errormsg,connect,idletime,delaytime
FROM withoutpartition

partition check
SELECT * FROM `shakeersreboot.sre_dataset.INFORMATION_SCHEMA.PARTITIONS`
WHERE table_name = 'testpartition';

sed -i 's/rc="Non HTTP response code: javax.net.ssl.SSLException"/rc="400"/g'  input.csv
